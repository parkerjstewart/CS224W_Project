{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_frame import TensorFrame, stype\n",
    "from torch_frame.nn import (\n",
    "    StypeWiseFeatureEncoder,\n",
    "    EmbeddingEncoder,\n",
    "    LinearBucketEncoder,\n",
    ")\n",
    "from torch_frame.data import Dataset\n",
    "from torch.nn import LayerNorm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating initial embeddings for our top 150 players using Torch Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our players data in from the CSV\n",
    "players = pd.read_csv(\"../data/player_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels controls the dimension size each column will have for our player rows after encoding\n",
    "channels = 128\n",
    "\n",
    "# set the stypes for each column in our data\n",
    "col_to_stype = {\n",
    "    \"player_id\": stype.numerical,\n",
    "    \"current_rank\": stype.numerical,\n",
    "    \"hand\": stype.categorical,\n",
    "    \"dob\": stype.numerical,\n",
    "    \"height\": stype.numerical,\n",
    "    \"country_num\": stype.categorical\n",
    "}\n",
    "\n",
    "# 2) Build a Dataset and materialize it -> computes col_stats and a TensorFrame\n",
    "ds = Dataset(df=players, col_to_stype=col_to_stype).materialize()\n",
    "tf_players = ds.tensor_frame\n",
    "col_stats  = ds.col_stats\n",
    "col_names_dict = tf_players.col_names_dict\n",
    "\n",
    "# 3) Create the stype-wise encoder with the computed stats\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical:  LinearBucketEncoder(post_module=LayerNorm(channels)),\n",
    "}\n",
    "\n",
    "encoder = StypeWiseFeatureEncoder(\n",
    "    out_channels=channels,\n",
    "    col_stats=col_stats,\n",
    "    col_names_dict=col_names_dict,\n",
    "    stype_encoder_dict=stype_encoder_dict,\n",
    ")\n",
    "\n",
    "# 4) Encode\n",
    "x, _meta = encoder(tf_players)  # x: [batch, num_cols, channels]\n",
    "\n",
    "player_emb = x.mean(dim=1) # simple average pooling over columns for now. we can get fancier later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our initial player embeddings, we can grab our edges to make our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edges = pd.read_csv(\"../data/edges.csv\")\n",
    "\n",
    "# --- node indices ---\n",
    "src = torch.from_numpy(edges[\"winner_idx\"].to_numpy()).long()\n",
    "dst = torch.from_numpy(edges[\"loser_idx\"].to_numpy()).long()\n",
    "\n",
    "# --- categorical encodings ---\n",
    "\n",
    "# surface is already 0/1/2 from SURFACE_MAP -> just one-hot\n",
    "surface = torch.from_numpy(edges[\"surface\"].to_numpy()).long()\n",
    "surface_oh = F.one_hot(surface, num_classes=3).float()           # [E, 3]\n",
    "\n",
    "# map tourney_level (e.g., 'A', 'M', 'G', ...) to ints then one-hot\n",
    "lvl_values = sorted(edges[\"tourney_level\"].unique())\n",
    "lvl2id = {lvl: i for i, lvl in enumerate(lvl_values)}\n",
    "tourney_level_idx = torch.from_numpy(edges[\"tourney_level\"].map(lvl2id).to_numpy()).long()\n",
    "tourney_level_oh = F.one_hot(tourney_level_idx, num_classes=len(lvl2id)).float()  # [E, L]\n",
    "\n",
    "# map round ('RR', 'R32', 'R16', 'QF', 'SF', 'F', ...) to ints then one-hot\n",
    "rnd_values = sorted(edges[\"round\"].unique())\n",
    "rnd2id = {rnd: i for i, rnd in enumerate(rnd_values)}\n",
    "round_idx = torch.from_numpy(edges[\"round\"].map(rnd2id).to_numpy()).long()\n",
    "round_oh = F.one_hot(round_idx, num_classes=len(rnd2id)).float()  # [E, R]\n",
    "\n",
    "# --- numerical features: best_of, days_ago ---\n",
    "\n",
    "best_of = torch.from_numpy(edges[\"best_of\"].to_numpy()).float().unsqueeze(1)  # [E, 1]\n",
    "# (optional) normalize best_of; not strictly necessary, but harmless\n",
    "best_of = (best_of - best_of.mean()) / (best_of.std() + 1e-6)\n",
    "\n",
    "days = torch.from_numpy(edges[\"days_ago\"].to_numpy()).float().unsqueeze(1)    # [E, 1]\n",
    "days = (days - days.mean()) / (days.std() + 1e-6)\n",
    "\n",
    "# --- full edge_attr: concat everything ---\n",
    "# shape: [E, 3 + L + R + 1 + 1]\n",
    "edge_attr = torch.cat(\n",
    "    [surface_oh, tourney_level_oh, round_oh, best_of, days],\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "E = edge_attr.size(0)\n",
    "\n",
    "# --- build bidirectional edges ---\n",
    "\n",
    "# original direction: winner -> loser\n",
    "edge_index_fwd = torch.stack([src, dst], dim=0)  # [2, E]\n",
    "edge_attr_fwd = edge_attr\n",
    "\n",
    "# reverse: loser -> winner\n",
    "edge_index_rev = torch.stack([dst, src], dim=0)  # [2, E]\n",
    "edge_attr_rev = edge_attr.clone()                # same match-level features\n",
    "\n",
    "# concat both directions\n",
    "edge_index = torch.cat([edge_index_fwd, edge_index_rev], dim=1)   # [2, 2E]\n",
    "edge_attr_bidir = torch.cat([edge_attr_fwd, edge_attr_rev], dim=0)  # [2E, feat_dim]\n",
    "\n",
    "# direction/type: 0 = \"won-against\" (winner->loser), 1 = \"lost-to\" (loser->winner)\n",
    "edge_type = torch.cat([\n",
    "    torch.zeros(E, dtype=torch.long),\n",
    "    torch.ones(E, dtype=torch.long)\n",
    "], dim=0)  # [2E]\n",
    "\n",
    "# --- split masks (per *original* edge), then expanded to bidirectional ---\n",
    "\n",
    "split_map = {\"train\": 0, \"val\": 1, \"test\": 2}\n",
    "edge_split = torch.from_numpy(edges[\"split\"].map(split_map).to_numpy()).long()  # [E]\n",
    "\n",
    "train_mask = edge_split == 0\n",
    "val_mask   = edge_split == 1\n",
    "test_mask  = edge_split == 2\n",
    "\n",
    "# for the bidirectional edges, just duplicate the masks\n",
    "train_mask_bidir = torch.cat([train_mask, train_mask], dim=0)  # [2E]\n",
    "val_mask_bidir   = torch.cat([val_mask,   val_mask],   dim=0)\n",
    "test_mask_bidir  = torch.cat([test_mask,  test_mask],  dim=0)\n",
    "\n",
    "# --- final PyG graph (message-passing graph; you can subset edge_index per phase) ---\n",
    "\n",
    "g = Data(\n",
    "    x=player_emb.detach(),                  # [N, C] from TorchFrame encoder\n",
    "    edge_index=edge_index,         # [2, 2E]\n",
    "    edge_attr=edge_attr_bidir,     # [2E, F]\n",
    "    edge_type=edge_type,           # [2E]\n",
    "    train_mask=train_mask_bidir,   # [2E]\n",
    "    val_mask=val_mask_bidir,       # [2E]\n",
    "    test_mask=test_mask_bidir,     # [2E]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's do a quick test to see how we preform before we use a GNN, let's get a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "def build_match_tensors(edges_df, z, split: str):\n",
    "    df = edges_df[edges_df[\"split\"] == split].reset_index(drop=True)\n",
    "\n",
    "    w_idx = torch.tensor(df[\"winner_idx\"].to_numpy(), dtype=torch.long)\n",
    "    l_idx = torch.tensor(df[\"loser_idx\"].to_numpy(), dtype=torch.long)\n",
    "\n",
    "    # --- player embeddings ---\n",
    "    z_w = z[w_idx]  # [M, D]\n",
    "    z_l = z[l_idx]  # [M, D]\n",
    "\n",
    "    # --- surface one-hot ---\n",
    "    surface = torch.tensor(df[\"surface\"].to_numpy(), dtype=torch.long)\n",
    "    surface_oh = F.one_hot(surface, num_classes=3).float()  # [M, 3]\n",
    "\n",
    "    # --- tourney_level one-hot (reuse same mapping as for edge_attr) ---\n",
    "    lvl_values = sorted(edges_df[\"tourney_level\"].unique())\n",
    "    lvl2id = {lvl: i for i, lvl in enumerate(lvl_values)}\n",
    "    lvl_idx = torch.tensor(df[\"tourney_level\"].map(lvl2id).to_numpy(), dtype=torch.long)\n",
    "    lvl_oh = F.one_hot(lvl_idx, num_classes=len(lvl2id)).float()  # [M, L]\n",
    "\n",
    "    # --- round one-hot ---\n",
    "    rnd_values = sorted(edges_df[\"round\"].unique())\n",
    "    rnd2id = {rnd: i for i, rnd in enumerate(rnd_values)}\n",
    "    rnd_idx = torch.tensor(df[\"round\"].map(rnd2id).to_numpy(), dtype=torch.long)\n",
    "    rnd_oh = F.one_hot(rnd_idx, num_classes=len(rnd2id)).float()  # [M, R]\n",
    "\n",
    "    # --- best_of (numeric, normalized) ---\n",
    "    best_of = torch.tensor(df[\"best_of\"].to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "    best_of = (best_of - best_of.mean()) / (best_of.std() + 1e-6)\n",
    "\n",
    "    # --- days_ago (numeric, normalized) ---\n",
    "    days = torch.tensor(df[\"days_ago\"].to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "    days = (days - days.mean()) / (days.std() + 1e-6)\n",
    "\n",
    "    # --- combine match-level features ---\n",
    "    match_feat = torch.cat(\n",
    "        [surface_oh, lvl_oh, rnd_oh, best_of, days], dim=1\n",
    "    )  # [M, F_match]\n",
    "\n",
    "    # --- construct positive & negative examples ---\n",
    "    # positive: (winner, loser) → label 1\n",
    "    X_pos = torch.cat([z_w, z_l, match_feat], dim=1)\n",
    "    y_pos = torch.ones(X_pos.size(0), dtype=torch.long)\n",
    "\n",
    "    # negative: (loser, winner) → label 0\n",
    "    X_neg = torch.cat([z_l, z_w, match_feat], dim=1)\n",
    "    y_neg = torch.zeros(X_neg.size(0), dtype=torch.long)\n",
    "\n",
    "    X = torch.cat([X_pos, X_neg], dim=0)  # [2M, 2D + F_match]\n",
    "    y = torch.cat([y_pos, y_neg], dim=0)  # [2M]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(\"../data/edges.csv\")  # same DataFrame used to build g\n",
    "\n",
    "player_emb_detached = player_emb.detach()\n",
    "X_train, y_train = build_match_tensors(edges, player_emb_detached, split=\"train\")\n",
    "X_val,   y_val   = build_match_tensors(edges, player_emb_detached, split=\"val\")\n",
    "X_test,  y_test  = build_match_tensors(edges, player_emb_detached, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MatchDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = MatchDataset(X_train, y_train)\n",
    "val_ds   = MatchDataset(X_val,   y_val)\n",
    "test_ds  = MatchDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)  \n",
    "val_loader   = DataLoader(val_ds,   batch_size=512, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=512, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.6878, val_acc=0.5880\n",
      "Epoch 2: loss=0.6781, val_acc=0.6106\n",
      "Epoch 3: loss=0.6689, val_acc=0.6242\n",
      "Epoch 4: loss=0.6598, val_acc=0.6309\n",
      "Epoch 5: loss=0.6518, val_acc=0.6388\n",
      "Epoch 6: loss=0.6450, val_acc=0.6377\n",
      "Epoch 7: loss=0.6400, val_acc=0.6371\n",
      "Epoch 8: loss=0.6356, val_acc=0.6337\n",
      "Epoch 9: loss=0.6321, val_acc=0.6332\n",
      "Epoch 10: loss=0.6291, val_acc=0.6270\n",
      "Epoch 11: loss=0.6272, val_acc=0.6292\n",
      "Epoch 12: loss=0.6251, val_acc=0.6247\n",
      "Epoch 13: loss=0.6235, val_acc=0.6264\n",
      "Epoch 14: loss=0.6221, val_acc=0.6253\n",
      "Epoch 15: loss=0.6206, val_acc=0.6298\n",
      "Epoch 16: loss=0.6203, val_acc=0.6281\n",
      "Epoch 17: loss=0.6192, val_acc=0.6230\n",
      "Epoch 18: loss=0.6180, val_acc=0.6247\n",
      "Epoch 19: loss=0.6171, val_acc=0.6281\n",
      "Epoch 20: loss=0.6166, val_acc=0.6225\n",
      "Final test accuracy: 0.628668171557562\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ---- tiny prediction head ----\n",
    "\n",
    "class MatchMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),  # 2 classes: 0 = (loser,winner), 1 = (winner,loser)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)  # returns logits [B, 2]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "in_dim = X_train.size(1)\n",
    "model = MatchMLP(in_dim=in_dim, hidden_dim=128).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def eval_loader(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "num_epochs = 20  # bump this as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "        total_examples += Xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_examples\n",
    "    val_acc = eval_loader(val_loader, model)\n",
    "    print(f\"Epoch {epoch+1}: loss={avg_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "test_acc = eval_loader(test_loader, model)\n",
    "print(\"Final test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv  \n",
    "\n",
    "class TwoWayEdgeAwareGAT(nn.Module):\n",
    "    def __init__(self, in_ch, hidden, out_ch, edge_dim):\n",
    "        super().__init__()\n",
    "        # separate params per direction\n",
    "        self.win1 = GATv2Conv(in_ch, hidden, edge_dim=edge_dim, add_self_loops=True)\n",
    "        self.los1 = GATv2Conv(in_ch, hidden, edge_dim=edge_dim, add_self_loops=True)\n",
    "        self.win2 = GATv2Conv(hidden, out_ch, edge_dim=edge_dim, add_self_loops=True)\n",
    "        self.los2 = GATv2Conv(hidden, out_ch, edge_dim=edge_dim, add_self_loops=True)\n",
    "        self.combine = nn.Linear(out_ch * 2, out_ch)  # concat → linear\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, edge_type):\n",
    "        # split edges by direction\n",
    "        idx_win = (edge_type == 0).nonzero(as_tuple=False).view(-1)\n",
    "        idx_los = (edge_type == 1).nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "        ei_win = edge_index[:, idx_win]\n",
    "        ei_los = edge_index[:, idx_los]\n",
    "        ea_win = edge_attr[idx_win]\n",
    "        ea_los = edge_attr[idx_los]\n",
    "\n",
    "        z_win = F.relu(self.win1(x, ei_win, ea_win))\n",
    "        z_los = F.relu(self.los1(x, ei_los, ea_los))\n",
    "        z_win = self.win2(z_win, ei_win, ea_win)\n",
    "        z_los = self.los2(z_los, ei_los, ea_los)\n",
    "\n",
    "        # combine the two message streams\n",
    "        z = torch.cat([z_win, z_los], dim=-1)   # or: z = z_win + z_los\n",
    "        z = self.combine(z)\n",
    "        return z\n",
    "\n",
    "edge_dim = g.edge_attr.shape[1]\n",
    "gnn = TwoWayEdgeAwareGAT(in_ch=player_emb.shape[1], hidden=128, out_ch=128, edge_dim=edge_dim)\n",
    "z = gnn(g.x, g.edge_index, g.edge_attr, g.edge_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1: loss=0.6679, val_acc=0.6005\n",
      "Epoch 2: loss=0.6283, val_acc=0.6089\n",
      "Epoch 3: loss=0.6196, val_acc=0.6185\n",
      "Epoch 4: loss=0.6191, val_acc=0.6146\n",
      "Epoch 5: loss=0.6163, val_acc=0.6140\n",
      "Epoch 6: loss=0.6161, val_acc=0.6179\n",
      "Epoch 7: loss=0.6158, val_acc=0.6185\n",
      "Epoch 8: loss=0.6151, val_acc=0.6225\n",
      "Epoch 9: loss=0.6143, val_acc=0.6202\n",
      "Epoch 10: loss=0.6144, val_acc=0.6163\n",
      "Epoch 11: loss=0.6144, val_acc=0.6163\n",
      "Epoch 12: loss=0.6124, val_acc=0.6174\n",
      "Epoch 13: loss=0.6136, val_acc=0.6185\n",
      "Epoch 14: loss=0.6113, val_acc=0.6168\n",
      "Epoch 15: loss=0.6121, val_acc=0.6168\n",
      "Epoch 16: loss=0.6120, val_acc=0.6191\n",
      "Epoch 17: loss=0.6105, val_acc=0.6140\n",
      "Epoch 18: loss=0.6136, val_acc=0.6179\n",
      "Epoch 19: loss=0.6105, val_acc=0.6163\n",
      "Epoch 20: loss=0.6106, val_acc=0.6129\n",
      "Epoch 21: loss=0.6095, val_acc=0.6168\n",
      "Epoch 22: loss=0.6092, val_acc=0.6174\n",
      "Epoch 23: loss=0.6102, val_acc=0.6106\n",
      "Epoch 24: loss=0.6112, val_acc=0.6185\n",
      "Epoch 25: loss=0.6092, val_acc=0.6196\n",
      "Epoch 26: loss=0.6099, val_acc=0.6179\n",
      "Epoch 27: loss=0.6085, val_acc=0.6230\n",
      "Epoch 28: loss=0.6091, val_acc=0.6196\n",
      "Epoch 29: loss=0.6076, val_acc=0.6163\n",
      "Epoch 30: loss=0.6082, val_acc=0.6151\n",
      "Epoch 31: loss=0.6086, val_acc=0.6157\n",
      "Epoch 32: loss=0.6071, val_acc=0.6168\n",
      "Epoch 33: loss=0.6071, val_acc=0.6174\n",
      "Epoch 34: loss=0.6073, val_acc=0.6185\n",
      "Epoch 35: loss=0.6074, val_acc=0.6185\n",
      "Epoch 36: loss=0.6061, val_acc=0.6202\n",
      "Epoch 37: loss=0.6075, val_acc=0.6202\n",
      "Epoch 38: loss=0.6077, val_acc=0.6174\n",
      "Epoch 39: loss=0.6084, val_acc=0.6179\n",
      "Epoch 40: loss=0.6068, val_acc=0.6191\n",
      "Epoch 41: loss=0.6087, val_acc=0.6129\n",
      "Epoch 42: loss=0.6058, val_acc=0.6179\n",
      "Epoch 43: loss=0.6056, val_acc=0.6196\n",
      "Epoch 44: loss=0.6054, val_acc=0.6146\n",
      "Epoch 45: loss=0.6060, val_acc=0.6163\n",
      "Epoch 46: loss=0.6053, val_acc=0.6163\n",
      "Epoch 47: loss=0.6052, val_acc=0.6174\n",
      "Epoch 48: loss=0.6067, val_acc=0.6196\n",
      "Epoch 49: loss=0.6054, val_acc=0.6185\n",
      "Epoch 50: loss=0.6056, val_acc=0.6185\n",
      "Epoch 51: loss=0.6052, val_acc=0.6202\n",
      "Epoch 52: loss=0.6054, val_acc=0.6213\n",
      "Epoch 53: loss=0.6064, val_acc=0.6208\n",
      "Epoch 54: loss=0.6046, val_acc=0.6196\n",
      "Epoch 55: loss=0.6051, val_acc=0.6208\n",
      "Epoch 56: loss=0.6039, val_acc=0.6163\n",
      "Epoch 57: loss=0.6052, val_acc=0.6157\n",
      "Epoch 58: loss=0.6042, val_acc=0.6208\n",
      "Epoch 59: loss=0.6054, val_acc=0.6202\n",
      "Epoch 60: loss=0.6057, val_acc=0.6185\n",
      "Epoch 61: loss=0.6051, val_acc=0.6163\n",
      "Epoch 62: loss=0.6037, val_acc=0.6191\n",
      "Epoch 63: loss=0.6047, val_acc=0.6191\n",
      "Epoch 64: loss=0.6040, val_acc=0.6185\n",
      "Epoch 65: loss=0.6049, val_acc=0.6146\n",
      "Epoch 66: loss=0.6045, val_acc=0.6202\n",
      "Epoch 67: loss=0.6039, val_acc=0.6185\n",
      "Epoch 68: loss=0.6034, val_acc=0.6196\n",
      "Epoch 69: loss=0.6033, val_acc=0.6191\n",
      "Epoch 70: loss=0.6049, val_acc=0.6213\n",
      "Epoch 71: loss=0.6039, val_acc=0.6179\n",
      "Epoch 72: loss=0.6039, val_acc=0.6185\n",
      "Epoch 73: loss=0.6031, val_acc=0.6151\n",
      "Epoch 74: loss=0.6040, val_acc=0.6196\n",
      "Epoch 75: loss=0.6032, val_acc=0.6174\n",
      "Epoch 76: loss=0.6041, val_acc=0.6185\n",
      "Epoch 77: loss=0.6037, val_acc=0.6191\n",
      "Epoch 78: loss=0.6040, val_acc=0.6196\n",
      "Epoch 79: loss=0.6016, val_acc=0.6157\n",
      "Epoch 80: loss=0.6023, val_acc=0.6213\n",
      "Epoch 81: loss=0.6025, val_acc=0.6185\n",
      "Epoch 82: loss=0.6026, val_acc=0.6208\n",
      "Epoch 83: loss=0.6032, val_acc=0.6185\n",
      "Epoch 84: loss=0.6009, val_acc=0.6179\n",
      "Epoch 85: loss=0.6026, val_acc=0.6202\n",
      "Epoch 86: loss=0.6020, val_acc=0.6179\n",
      "Epoch 87: loss=0.6012, val_acc=0.6168\n",
      "Epoch 88: loss=0.6034, val_acc=0.6163\n",
      "Epoch 89: loss=0.6007, val_acc=0.6163\n",
      "Epoch 90: loss=0.6012, val_acc=0.6196\n",
      "Epoch 91: loss=0.6015, val_acc=0.6163\n",
      "Epoch 92: loss=0.6025, val_acc=0.6174\n",
      "Epoch 93: loss=0.6017, val_acc=0.6213\n",
      "Epoch 94: loss=0.6025, val_acc=0.6202\n",
      "Epoch 95: loss=0.6016, val_acc=0.6253\n",
      "Epoch 96: loss=0.6008, val_acc=0.6185\n",
      "Epoch 97: loss=0.5993, val_acc=0.6225\n",
      "Epoch 98: loss=0.6009, val_acc=0.6208\n",
      "Epoch 99: loss=0.6005, val_acc=0.6168\n",
      "Epoch 100: loss=0.6011, val_acc=0.6208\n",
      "Final test accuracy: 0.6281038374717833\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import GATv2Conv  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ========= 1. Precompute per-match tensors ONCE =========\n",
    "\n",
    "# row indices per split (on CPU)\n",
    "train_rows = torch.tensor(edges.index[edges[\"split\"] == \"train\"].to_numpy(), dtype=torch.long)\n",
    "val_rows   = torch.tensor(edges.index[edges[\"split\"] == \"val\"].to_numpy(),   dtype=torch.long)\n",
    "test_rows  = torch.tensor(edges.index[edges[\"split\"] == \"test\"].to_numpy(),  dtype=torch.long)\n",
    "\n",
    "# player indices per match (move to device)\n",
    "winner_idx_all = torch.tensor(edges[\"winner_idx\"].to_numpy(), dtype=torch.long, device=device)\n",
    "loser_idx_all  = torch.tensor(edges[\"loser_idx\"].to_numpy(),  dtype=torch.long, device=device)\n",
    "\n",
    "# --- categorical encodings computed ONCE ---\n",
    "\n",
    "# surface: already 0/1/2\n",
    "surface_all = torch.tensor(edges[\"surface\"].to_numpy(), dtype=torch.long, device=device)\n",
    "surface_oh  = F.one_hot(surface_all, num_classes=3).float()  # [M, 3]\n",
    "\n",
    "# tourney_level → ids → one-hot\n",
    "lvl_values = sorted(edges[\"tourney_level\"].unique())\n",
    "lvl2id = {lvl: i for i, lvl in enumerate(lvl_values)}\n",
    "tourney_level_idx = torch.tensor(\n",
    "    edges[\"tourney_level\"].map(lvl2id).to_numpy(), dtype=torch.long, device=device\n",
    ")\n",
    "tourney_level_oh = F.one_hot(tourney_level_idx, num_classes=len(lvl2id)).float()  # [M, L]\n",
    "\n",
    "# round → ids → one-hot\n",
    "rnd_values = sorted(edges[\"round\"].unique())\n",
    "rnd2id = {rnd: i for i, rnd in enumerate(rnd_values)}\n",
    "round_idx = torch.tensor(\n",
    "    edges[\"round\"].map(rnd2id).to_numpy(), dtype=torch.long, device=device\n",
    ")\n",
    "round_oh = F.one_hot(round_idx, num_classes=len(rnd2id)).float()  # [M, R]\n",
    "\n",
    "# --- numeric features (normed once) ---\n",
    "\n",
    "best_of_all = torch.tensor(edges[\"best_of\"].to_numpy(), dtype=torch.float32, device=device).unsqueeze(1)\n",
    "days_all    = torch.tensor(edges[\"days_ago\"].to_numpy(), dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "best_of_all = (best_of_all - best_of_all.mean()) / (best_of_all.std() + 1e-6)\n",
    "days_all    = (days_all    - days_all.mean())    / (days_all.std()    + 1e-6)\n",
    "\n",
    "# --- final per-match features (constant) ---\n",
    "\n",
    "match_feat_all = torch.cat([surface_oh, tourney_level_oh, round_oh, best_of_all, days_all], dim=1)\n",
    "match_feat_dim = match_feat_all.size(1)  # 3 + |lvl| + |round| + 1 + 1\n",
    "\n",
    "# message-passing edges: USE ONLY TRAIN EDGES to avoid leakage\n",
    "train_edge_mask = g.train_mask.to(device)         # [2E] bool\n",
    "edge_index_train = g.edge_index[:, train_edge_mask].to(device)\n",
    "edge_attr_train  = g.edge_attr[train_edge_mask].to(device)\n",
    "edge_type_train  = g.edge_type[train_edge_mask].to(device)\n",
    "\n",
    "# ========= 2. Dataset that holds ONLY row indices =========\n",
    "\n",
    "class MatchIndexDataset(Dataset):\n",
    "    def __init__(self, row_indices: torch.Tensor):\n",
    "        self.row_indices = row_indices\n",
    "    def __len__(self):\n",
    "        return self.row_indices.size(0)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.row_indices[idx]\n",
    "\n",
    "train_ds = MatchIndexDataset(train_rows)\n",
    "val_ds   = MatchIndexDataset(val_rows)\n",
    "test_ds  = MatchIndexDataset(test_rows)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=512, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=512, shuffle=False)\n",
    "\n",
    "# ========= 3. GNN: two-way edge-aware GAT =========\n",
    "\n",
    "from torch_geometric.nn import GINEConv\n",
    "\n",
    "from torch_geometric.nn import GINEConv\n",
    "\n",
    "class TwoWayEdgeAwareGIN(nn.Module):\n",
    "    def __init__(self, in_ch, hidden, out_ch, edge_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        def make_mlp(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, out_dim),\n",
    "            )\n",
    "\n",
    "        # GINE for each direction\n",
    "        self.win_conv = GINEConv(make_mlp(in_ch, out_ch), edge_dim=edge_dim)\n",
    "        self.los_conv = GINEConv(make_mlp(in_ch, out_ch), edge_dim=edge_dim)\n",
    "\n",
    "        # combine directional embeddings\n",
    "        self.combine = nn.Linear(out_ch * 2, out_ch)\n",
    "\n",
    "        # project original node features to same dim for residual\n",
    "        if in_ch == out_ch:\n",
    "            self.skip = nn.Identity()\n",
    "        else:\n",
    "            self.skip = nn.Linear(in_ch, out_ch)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, edge_type):\n",
    "        # split edges\n",
    "        idx_win = (edge_type == 0).nonzero(as_tuple=False).view(-1)\n",
    "        idx_los = (edge_type == 1).nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "        ei_win = edge_index[:, idx_win]\n",
    "        ei_los = edge_index[:, idx_los]\n",
    "        ea_win = edge_attr[idx_win]\n",
    "        ea_los = edge_attr[idx_los]\n",
    "\n",
    "        # neighbor messages\n",
    "        z_win = self.win_conv(x, ei_win, ea_win)  # [N, out_ch]\n",
    "        z_los = self.los_conv(x, ei_los, ea_los)  # [N, out_ch]\n",
    "\n",
    "        # directional combine\n",
    "        z_dir = torch.cat([z_win, z_los], dim=-1)   # [N, 2*out_ch]\n",
    "        z_dir = self.combine(z_dir)                # [N, out_ch]\n",
    "\n",
    "        # residual + nonlinearity + dropout\n",
    "        z = z_dir + self.skip(x)                   # include original node vec\n",
    "        z = F.relu(z)\n",
    "        z = self.dropout(z)\n",
    "\n",
    "        return z  # [N, out_ch]\n",
    "\n",
    "\n",
    "# ========= 4. Prediction head MLP =========\n",
    "class MatchMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),  # 0 = (loser,winner), 1 = (winner,loser)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "# ========= 5. Build batch features from z + row indices (no duplicate encodings) =========\n",
    "\n",
    "def make_batch_features(z, batch_rows):\n",
    "    \"\"\"\n",
    "    z: [N, D] node embeddings from GNN\n",
    "    batch_rows: [B] indices into edges/matches\n",
    "    returns X_batch: [2B, feat_dim], y_batch: [2B]\n",
    "    \"\"\"\n",
    "    batch_rows = batch_rows.to(device)\n",
    "\n",
    "    w_idx = winner_idx_all[batch_rows]   # [B]\n",
    "    l_idx = loser_idx_all[batch_rows]    # [B]\n",
    "\n",
    "    z_w = z[w_idx]  # [B, D]\n",
    "    z_l = z[l_idx]  # [B, D]\n",
    "\n",
    "    mf = match_feat_all[batch_rows]  # [B, match_feat_dim]\n",
    "\n",
    "    # positive: (winner, loser) → label 1\n",
    "    X_pos = torch.cat([z_w, z_l, mf], dim=1)\n",
    "    y_pos = torch.ones(X_pos.size(0), dtype=torch.long, device=device)\n",
    "\n",
    "    # negative: (loser, winner) → label 0\n",
    "    X_neg = torch.cat([z_l, z_w, mf], dim=1)\n",
    "    y_neg = torch.zeros(X_neg.size(0), dtype=torch.long, device=device)\n",
    "\n",
    "    X_batch = torch.cat([X_pos, X_neg], dim=0)\n",
    "    y_batch = torch.cat([y_pos, y_neg], dim=0)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "# ========= 6. Instantiate models, optimizer, etc. =========\n",
    "\n",
    "edge_dim = g.edge_attr.shape[1]\n",
    "gnn_hidden = 128\n",
    "gnn_out = 128\n",
    "\n",
    "gnn = TwoWayEdgeAwareGIN(\n",
    "    in_ch=g.x.shape[1],\n",
    "    hidden=gnn_hidden,\n",
    "    out_ch=gnn_out,\n",
    "    edge_dim=edge_dim,\n",
    ").to(device)\n",
    "\n",
    "head_in_dim = 2 * gnn_out + match_feat_dim\n",
    "head = MatchMLP(in_dim=head_in_dim, hidden_dim=128).to(device)\n",
    "\n",
    "params = list(gnn.parameters()) + list(head.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "gnn_lr  = 1e-4   # smaller LR for GNN\n",
    "head_lr = 1e-5   # larger LR for prediction head\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\": gnn.parameters(),  \"lr\": gnn_lr},\n",
    "        {\"params\": head.parameters(), \"lr\": head_lr},\n",
    "    ],\n",
    "    weight_decay=1e-5,   # optional\n",
    ")\n",
    "\n",
    "# ========= 7. Eval helper (compute z once per split) =========\n",
    "\n",
    "def eval_split(loader, gnn, head):\n",
    "    gnn.eval()\n",
    "    head.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        z = gnn(\n",
    "            g.x.to(device),\n",
    "            edge_index_train,\n",
    "            edge_attr_train,\n",
    "            edge_type_train,\n",
    "        )\n",
    "        for batch_rows in loader:\n",
    "            batch_rows = batch_rows.squeeze(-1) if batch_rows.ndim > 1 else batch_rows\n",
    "            Xb, yb = make_batch_features(z, batch_rows)\n",
    "            logits = head(Xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "# ========= 8. Training loop (end-to-end) =========\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    gnn.train()\n",
    "    head.train()\n",
    "\n",
    "    # shuffle match indices each epoch\n",
    "    perm = torch.randperm(train_rows.size(0))\n",
    "    train_rows_shuffled = train_rows[perm].to(device)\n",
    "    \n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    # build the total loss from mini-batches of matches\n",
    "    for start in range(0, train_rows_shuffled.size(0), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_rows = train_rows_shuffled[start:end]\n",
    "        optimizer.zero_grad()\n",
    "        z = gnn(\n",
    "            g.x.to(device),\n",
    "            edge_index_train,\n",
    "            edge_attr_train,\n",
    "            edge_type_train,\n",
    "        )  # [N, gnn_out]  # [B]\n",
    "\n",
    "        Xb, yb = make_batch_features(z, batch_rows)   # [2B, feat_dim], [2B]\n",
    "        logits = head(Xb)\n",
    "        loss = criterion(logits, yb)                  # scalar\n",
    "\n",
    "        # accumulate loss *without* breaking the graph\n",
    "        total_loss = total_loss + loss * yb.size(0)\n",
    "        total_examples += yb.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / total_examples\n",
    "\n",
    "    # single backward through the whole graph for this epoch\n",
    "\n",
    "    # evaluation\n",
    "    val_acc = eval_split(val_loader, gnn, head)\n",
    "    print(f\"Epoch {epoch+1}: loss={avg_loss.item():.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "test_acc = eval_split(test_loader, gnn, head)\n",
    "print(\"Final test accuracy:\", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
